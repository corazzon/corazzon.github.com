---
layout: post
title: "[도서 리뷰] 파이썬으로 웹 크롤러 만들기(2판) : 초간단 나만의 웹 크롤러로 원하는 데이터를 가져오는 방법"
tagline: "이 리뷰는 한빛미디어의 <나는 리뷰어다> 이벤트를 통해 책을 제공받아 작성했습니다. "
description: "한빛미디어 -  파이썬으로 웹 크롤러 만들기(2판): 초간단 나만의 웹 크롤러로 원하는 데이터를 가져오는 방법" 
category: 크롤링, 스크랩, crawling, python, request, beautifulsoup
---

{% include JB/setup %}

파이썬으로 웹 크롤러 만들기(2판)


<img src="https://i.imgur.com/Z5xRVQH.jpg">


이 책의 초판도 인상적으로 읽었는데, 2판이 나와서 다시 읽어보게 되었다.
기존 초판에서 4, 5, 16장이 추가되었다고 한다.

<img src="https://i.imgur.com/dEOJYQN.png">

프로그래밍 책을 읽을 때 가장 먼저 하는 일은 github 저장소가 있는지 찾는다.
이 책의 저자도 github 페이지에 책의 소스코드를 공개하고 있고 주피터 노트북을 통해 바로 실습할 수 있도록 .ipynb 확장자로 파일을 제공하고 있다.
또, 초판에서는 소스코드를 .py 형태로 제공했는데 2판이 나오며 .ipynb 형태로 제공하고 있기 때문에 주피터노트북과 google colabortory를 통해 코드를 바로 실행해 볼 수있게 되었다.

[https://github.com/REMitchell/python-scraping](https://github.com/REMitchell/python-scraping)

<img src="https://i.imgur.com/67FA4sY.png">

소스코드를 열어볼 때는 로컬장비에 클론을 받아 주피터노트북으로 열어보는 방법도 있지만, 아래의 링크처럼 바로 Colaboratory로 열어 소스코드를 실행해 볼 수 있다.
[https://colab.research.google.com/github/REMitchell/python-scraping/](https://colab.research.google.com/github/REMitchell/python-scraping/)

위에 있는 colab URL을 실행하면 바로 소스코드를 실행해 볼 수 있다.
또, 개발서적을 볼 때 텍스트 보다 소스코드를 먼저보고 이 소스코드가 뭘 의미할지 먼저 고민해 보고 텍스트를 보는데 이렇게 프로그래밍 관련 책을 읽을 때는 소스코드를 먼저 실행해 보면 텍스트를 봤을 때 더 도움이 되는 것 같다.

크롤링을 할 때 보통 유명사이트를 크롤링하는 예제로 만들어질 때가 많은데 이 책은 크롤링을 위해 사이트를 임의로 만들었다. 이렇게 별도의 사이트를 만드는데는 실습하고자 하는 의도를 잘 표현할 수 있다는 점과 사이트의 레이아웃이 변경되거나 했을 때 책의 소스코드가 돌아가지 않는 점을 방지할 수 있을거 같다.
크롤링을 위한 사이트를 만들어 놓았기 때문에 사이트의 내용이 변경되어 책의 소스코드를 사용할 수 없게 되는 일을 방지할 수 있다는 점이 좋았다.

<img src="https://i.imgur.com/MoqqMYg.png">

또, 이렇게 실습 사이트를 만들었을 때 실습용으로 만든 사이트이기 때문에 서비스에 부담을 주지 않는 것도 장점일 것 같다. 사이트를 크롤링하면 트래픽이 몰릴 수 밖에 없기 때문에 서비스에 부담을 주게 되는데 실습용으로 제작된 사이트에서 여러 배려를 느낄 수 있었다.


웹 크롤링 혹은 스크래핑은 책에서 얘기하는 것 처럼 프로그래밍을 전문적으로 다루는 사람이든 아니든 누구든 흥미로워 하는 분야 중에 하나인것 같다.
또, 웹 크롤링을 위해서는 웹에 대한 전반적인 지식을 필요로 한다.
그래서 크롤링으로 프로그래밍을 배우게 된다면 웹에 대한 전반적인 내용을 배울 수 있는 주제라는 생각이 든다.

그래서 웹 스크래핑을 이해하기 위해서는 프로그래밍 기초지식도 필요하지만 html 이라든지 css, 자바스크립트 등에 대한 이해도 필요로 한다.


## 다양한 형식으로 저장하기

데이터를 수집해서 어떻게 저장해서 처리해야 하는지도 중요한데, 이 책은 csv형태의 파일로 저장하는 코드 뿐만 아니라 데이터베이스를 활용해서 저장하는 방법까지 다루고 있다.

## 텍스트 마이닝 기법(ngram, 마르코프 모델)

이 책에서 가장 인상적이었던 부분은 텍스트데이터를 전처리 하고 다루는 방법에 대한 내용이다.
크롤링과는 조금 거리가 있는 내용일 수도 있지만 수집한 비정형 데이터를 분석하기 위해서는 텍스트 마이닝 기술을 가지고 있으면 좀 더 다양한 분석을 해볼 수 있다. 또, 웹상에서 수집한 데이터는 텍스트 데이터가 많은데 아무리 수집을 많이 한다고 해도 의미를 찾을 수 없다면 무용한 일이 될 수도 있을 것이다.
초판에서도 이 책에서 인상적이었던 부분은 이런 텍스트마이닝 기법이었다.
게다가 머신러닝이나 딥러닝에서 활용되고 있는 마르코프 모델에 대한 내용까지 다루고 있다.


## 이미지 처리와 텍스트 인식
웹 상에서 가져온 이미지에 있는 텍스트를 다룰 수 있도록 OCR 라이브러리도 다루고 있다. 그리고 수집된 이미지를 학습해서 이미지의 문자를 인식할 수 있는 머신러닝 기술에 대한 설명도 함께 하고 있다.


## 테스트

웹사이트를 주기적으로 크롤링하다보면 어느 날 사이트가 변경이 되어 작성했던 크롤링 스크립트가 동작하지 않는 경험을 하기도 한다. 또 테스트코드를 작성하는 것은 좋은 습관 중에 하나이기도 하다.
이 책은 이런 코드들을 모두 주피터 노트북에서 실행할 수 있는 소스코드로 제공하고 있다.


## 저작권
크롤링을 통해 데이터를 수집할 때 가끔 저작권을 간과해서 이슈가 되는 사례를 종종 봐왔다.
크롤링을 하기 전에 수집을 해도 되는 데이터인지 저작권에는 문제가 없는지 합법성과 윤리에 대해서도 구체적인 사례를 통해 설명하고 있다.


초판의 내용도 좋았기 때문에 어떤 내용이 추가되었을 지 궁금했는데 크롤링을 하면 대량의 페이지를 가져올 때 좀 더 빠르게 혹은 효율적으로 작업하기 위한 병렬처리 내용이 추가된 것도 인상적이다.

책의 소스코드도 잘 정리되어 있어서 실습과 함께 볼 수 있는 점이 좋았다.
