---
layout: post
title: "[도서 리뷰] LLM 엔지니어링"
tagline: "한빛미디어 서평단 <나는리뷰어다> 활동을 위해서 책을 협찬 받아 작성된 서평입니다."
description: "실무 중심의 LLM 엔지니어링 가이드"
category: LLM, LLMOps
---

한빛미디어 서평단 <나는리뷰어다> 활동을 위해서 책을 협찬 받아 작성된 서평입니다.

<img src="https://i.imgur.com/yHjCjxv.jpeg" width="600">

『LLM 엔지니어링 – RAG, 파인튜닝, LLMOps로 완성하는 실무 중심의 LLM 애플리케이션 개발』은 실제 제품 수준의 LLM 애플리케이션을 개발하고 배포할 수 있도록 돕는 실전 중심의 안내서이다. 이 책의 가장 큰 특징은 단순한 API 호출이나 모델 응용에 그치지 않고, 하나의 완결된 프로젝트를 통해 LLM 개발의 전 과정을 따라가게 한다는 점이다. 책 전체는 'LLM Twin'이라는 개인 맞춤형 AI 캐릭터를 구현하는 과정을 중심으로 구성되어 있으며, 이를 통해 독자는 LLM 기반 애플리케이션의 기획, 개발, 배포, 운영까지 아우르는 포괄적인 경험을 하게 된다.

초반부에서는 LLM Twin이라는 개념을 통해 개인의 글쓰기 스타일과 성격을 모방하는 AI의 필요성과 목적을 설명하고, 이를 구현하기 위한 시스템 아키텍처를 소개한다. 이 부분에서는 단순히 모델을 다루는 기술적인 측면뿐만 아니라, 하나의 제품으로서 LLM 애플리케이션이 가져야 할 구조와 기능에 대한 전반적인 이해를 제공한다. 이어지는 장에서는 파이썬 생태계를 기반으로 프로젝트를 설치하고, 실습에 사용할 MLOps 및 LLMOps 도구들, 벡터 검색 DB인 Qdrant, NoSQL DB인 MongoDB, 그리고 클라우드 인프라로서 AWS 준비 방법 등을 다룬다.

<img src="https://i.imgur.com/let2aTv.jpeg" width="600">

중반부에서는 본격적인 데이터 엔지니어링과 모델 학습, RAG 파이프라인 설계에 들어간다. 웹스크래핑을 통해 데이터를 수집하고, 이를 전처리하여 벡터화한 후 저장소에 적재하는 파이프라인을 직접 구현하게 된다. 이를 바탕으로 RAG(Retrieval-Augmented Generation) 아키텍처를 구성하며, 단순한 검색-생성 결합이 아닌, 문서 기반 지시문 및 응답 형태로 확장된 고급 RAG 구성을 실습할 수 있다. 고급 RAG 구성은 실제 서비스 환경에서의 사용자 질의 대응력 향상과 밀접한 연관이 있으며, 이 책은 그것을 실제 코드 수준에서 상세히 안내한다.

지도 학습 기반의 파인튜닝 장에서는 LoRA와 QLoRA 같은 최신 경량화 기법을 활용하여 학습 비용을 줄이면서도 모델의 성능을 개선하는 방법을 제시한다. 특히 지시문 데이터셋을 직접 생성하고 이를 기반으로 SFT(Supervised Fine-Tuning)를 적용하는 과정은, 단순히 공개된 데이터셋을 이용하는 것이 아니라 자신만의 맞춤형 데이터로 모델을 조정하는 경험을 제공한다. 이어서 선호도 기반 파인튜닝에서는 최근 주목받고 있는 DPO(Direct Preference Optimization) 기법을 다룬다. 사용자 선호 데이터를 수집하고 이를 바탕으로 모델이 보다 자연스럽고 일관성 있게 응답할 수 있도록 정렬 파인튜닝을 수행하는 이 과정을 통해, 사용자 맞춤형 AI 응답 품질을 높이는 실제 전략을 배울 수 있다.

후반부에서는 모델 평가와 추론 최적화, 서비스 배포와 운영까지 이어진다. 모델 성능 평가에서는 BLEU, ROUGE 같은 평가 지표뿐만 아니라, 실제 사용 맥락에서의 응답 품질을 측정하는 평가 방법론도 함께 소개된다. 추론 최적화 부분에서는 양자화와 모델 병렬 처리 전략이 등장하며, 이는 고사양 장비 없이도 추론 속도와 비용을 개선하려는 개발자들에게 특히 유용하다. 이 과정에서도 Hugging Face의 Optimum과 같은 라이브러리 활용법이 함께 안내된다.

<img src="https://i.imgur.com/Sqi1Igy.jpeg" width="600">

배포 파트에서는 FastAPI 기반의 RESTful 서버 구현을 통해 추론 API를 설계하고, 오토스케일링을 포함한 클라우드 배포 전략까지 다룬다. 모놀리식 아키텍처와 마이크로서비스 아키텍처를 비교 분석하면서 서비스 구조 설계에 대한 이해를 높이고, 급증하는 트래픽을 처리할 수 있는 탄력적 인프라 구축까지 안내한다. 이 부분은 실무 환경에서 LLM을 실제로 활용하려는 팀과 조직에게 매우 실용적인 내용을 담고 있다.

마지막으로 LLMOps에 관한 챕터에서는 DevOps, MLOps, LLMOps의 차이점을 설명하고, 실험 추적, 버전 관리, 테스트, 모니터링, 재현 가능성 등 운영 환경에서의 안정성과 신뢰성을 확보하기 위한 핵심 원칙들을 실습 중심으로 제시한다. 특히, MLflow, Weights & Biases(W\&B), DVC 등 LLM 실험 및 버전 관리를 위한 툴체인 구성법은 실제 조직 내 모델 운영과 유지보수에 실질적인 도움을 준다.

<img src="https://i.imgur.com/ZdWyzOs.jpeg" width="600">

이 책의 장점은 최신 LLM 기술 트렌드를 충실히 반영하면서도 단순한 개념 설명에 그치지 않고, 실제 코드와 프로젝트 흐름을 통해 독자가 직접 구현하며 배울 수 있도록 구성되어 있다는 점이다. RAG, LoRA, QLoRA, DPO, Qdrant, FastAPI, LLMOps 등 현재 LLM 엔지니어링 분야에서 가장 핵심적인 기술들을 모두 아우르며, 이들을 실무에 적용하는 데 필요한 모든 구성 요소를 빠짐없이 소개한다.

다만 이 책은 중급 이상의 개발자를 대상으로 한다. 파이썬 기본 문법, REST API 설계, 리눅스 기반 서버 운용, 도커, 데이터베이스, Hugging Face 라이브러리 등에 대한 사전 지식이 없다면 진입 장벽이 있을 수 있다. 그러나 이 모든 도구를 이미 활용해본 독자라면, 이 책은 실질적인 기술 내공을 한 단계 끌어올릴 수 있는 실습형 가이드이다.

『LLM 엔지니어링』은 단순히 AI를 ‘사용’하는 것 뿐만 아니라, AI를 ‘구현하고 운영’하는 개발자와 엔지니어, 기술 리더를 위한 실무 지침서이다. 생성형 AI 시대에 개인화된 서비스 개발과 LLMOps 체계를 도입하고자 할 때 도움이 되는 책이다.
