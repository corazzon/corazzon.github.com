---
layout: post
title: "[NDC후기] 소프트웨어 2.0을 활용한 게임 어뷰징 검출"
tagline: "2018년 4월 26일에 NDC에서 발표된 `소프트웨어 2.0을 활용한 게임 어뷰징 검출`을 듣고 정리한 내용입니다."
description: " 소프트웨어 2.0을 활용한 게임 어뷰징 검출
"
category: "python, 머신러닝, 딥러닝, NDC"
tags: [python, ml, 머신러닝, machine learning, 기계학습, 딥러닝, software2.0, 소프트웨어2.0, 게임어뷰징검출]
---

{% include JB/setup %}

소프트웨어 2.0 소개

<iframe src="//www.slideshare.net/slideshow/embed_code/key/Ag4ySi7GGiuKbk" width="595" height="485" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;" allowfullscreen> </iframe> 
<div style="margin-bottom:5px"> <strong> 
<a href="//www.slideshare.net/ssuser163469/20-95081863" title="소프트웨어 2.0을 활용한 게임 어뷰징 검출" target="_blank">소프트웨어 2.0을 활용한 게임 어뷰징 검출</a> </strong> 
</div>



```
그간 NDC에 가고 싶었지만 매번 늦게 신청해서 못 갔는데, 
이번에는 첫 날 신청을 해서! 드디어 처음으로 NDC에 가보게 되었다.
NDC에서 가장 듣고 싶었던 세션인 소프트웨어 2.0에 대한 발표를 듣고 정리한 내용이다.
발표자 분은 예전에 같은 회사에서 일했던 롤모델같은 분이기도 하다.
NDC뿐만 아니라 파이콘에서도 좋은 발표를 많이 해주셨었다.
이번에도 역시나 너무 좋은 발표로 자연어 처리에 관심이 많은 내게 도움이 되는 발표였다.
발표를 들으며 빠르게 타이핑한 내용을 남겨본다.
```



### 발표를 듣기 전에 미리 읽어 볼 것

* [소프트웨어 2.0.md](https://gist.github.com/haje01/d2518ea998ab2de102b072fed600c0a4)


### 마르코프 연쇄로 랜덤 이름 찾기

> 게임을 만들다가 좋은 성과를 거두지 못해 이유를 생각해 봤다.

### 운영의 중요성
- 운영은 유저와의 소통이 중요하다. 유저는 디데일하게 친절하게 왜 접었는지 재미없는지 얘기해 주지 않는다.
- 이걸 보는 방법은 데이터를 보는 것이다.
- 그래서 데이터 엔지니어링부터 시작했다.
- 로그를 중앙으로 모으고 기계학습으로 어뷰징 검출을 시도해 보고 제작년 NDC에서 발표를 한 적이 있다.

### 로그 수집
- 수집 된 로그를 하둡을 통해 정제
- 수작업으로 개발한 특성(Feature)을 이용해
- 스패머 검출하는 로직에 대한 소개


### 2016년 발표에서 몇 가지 달라진 것

1. 하둡에서 스파크를 사용하는 것으로 바뀌었다.
- 무엇보다 빠르고 사용하기 편하다.
- 하둡보다 월등하게 좋아진 플랫폼이다.

2. 수작업된 특성에서 데이터에서 학습된 특성으로
- 데이터에서 컴퓨터가 스스로 학습을 해서 스스로 어뷰저를 찾도록 하고 있다.

3. 수동 제재에서 자동 제재로
- 제재를 하기 전에 GM과 협의를 해서 제재를 했지만 이제 어느정도 안정화 단계에 이르러서 사람을 거치지 않고 로그를 중앙에 모으고 기계학습을 하고 사람의 손을 거치지 않고 자동으로 제재한다.

### 기존에도 여러 방법을 통해 게임어뷰저를 제재하고 있을텐데

1. 이걸 기계학습으로 하는 이유는 게임 본래 데이터의 특성 때문이다.
- 내용이 굉장이 많다. 아이템, 강화, 퀘스트 등 하나의 이벤트로 보고 관련 정보를 쓰다보면 종류와 용량이 많아지고 기획 내용에 따라 포맷이 달라진다.

2. 다양한 특성을 동시에 고려해야
- 여러 특성을 같이 봐야 한다. 아이피 대역이 중국인가? 플레이 한지 며칠이 되었나? 플레이 시간은 얼마고
- 사람은 동시에 몇 개의 특성이 늘어나면 판단하기가 점점 힘들어 진다.

3. 24시간 모니터링 & 자동 제재
- 기계학습을 통해 어뷰징 제재를 하고 있다.

### 사용중인 어뷰징 검출 특성들(일부)
- 플레이시간, 스킬사용, 던전 클리어 유료결제 한 적이 있는가 여러 가지 특성을 종합적으로 살펴보고 있다.
- 피처엔지니어링을 통해 뽑아낸 특성들을 포함해서 모든 특성들을 종합적으로 판단하고 있다.

## 소프트웨어 2.0 소개
- 최근 인공지능이나 기계학습이 화두가 되고 있다. 여러 학문 분야 중에 자기의 입장에 따라 기계학습을 다양하게 이해하고 학습하고 있다.
- 연결주의자는 기계학습은 사람의 뇌를 모사함 그래서 뉴럴넷으로 구현
- 베이즈 주의자는 베이즈 정리로 설명
- 논리학 쪽에서는 심볼릭 로직인 기호주의자는 기호로 사회현상을 귀납적으로 추론한다.

- 진화주의자나 유추주의자도 기계학습을 바라보고 해석하고 있다.
- 마스터 알고리즘이라는 책에서 이미지를 가져와서 몇 가지를 추가함


- 개발자의 관점에서는 데이터에서 학습되는 코드로 볼 수 있지 않나? 생각됨
- 코드 베이스로 서비스까지 이루어지니까 기존의 소프트웨어와 다른 것일까? 혼자만의 생각을 하게 되었다.

### 소프트웨어 2.0 `Andrej Karpathy`라는 딥러닝계의 연구자
* [Andrej Karpathy Academic Website](https://cs.stanford.edu/people/karpathy/)
- 뉴럴넷은 또 다른 분류기가 아니라 근본적인 변화다. 그것은 소프트웨어 2.0이다. 메니페스토처럼 선언했다.
- 실세계의 문제들중 많은 것이 프로그래머가 프로그램을 짜기 보다 모으는 것이 훨씬 더 쉬운 속성을 가지고 있다.

- 미래의 프로그래머 중 많은 이들은 뉴럴넷에 공급할 데이터를 수집, 정리, 조작, 라벨링하고 분석 및 시각화 하는 일을 할 것이다.
- 넓게 보면 뉴럴넷만이 SW2.0을 뜻하지는 않으며, 조심스럽지만 개발자의 관점에서 기계학습대신 소프트웨어2.0으로 발표제목을 걸었다.

## 소프트웨어 1.0과 2.0의 흐름

### 1.0
구현된 서비스가 동작하고 데이터가 나온다.
서버가 다루는 다량의 로그

### 2.0
이미 구현이 되어있고 그 구현에서 동작을 하고 있다. 그 동작에서 데이터가 뽑아짐
우리가 원하는 기능을 구현하게 진행된다.

### SW2.0에 필요한 스킬들

* 데이터 특성 파악 - 탐색적 데이터 분석(EDA)
* 대용량 데이터 다루기 - 빅데이터 처리

### SW 2.0을 위한 도구
- 프로그래밍 언어(전처리 분야에는 이 부분이 꼭 필요)
- 시각화 도구
- 기계학습 라이브러리

#### Spark
- 꼭 빅데이터가 아니어도 가능하지만...
 - 규모 가변성
 - 많은 데이터가 영리한 알고리즘을 이긴다.
- 최고의 빅데이터 플랫폼
- 또한, 범용 분산 처리 플랫폼
- 머신하나에 의존하는 플랫폼을 쓰면 빅데이터에 적용이 어렵다. 스파크를 쓰면 클러스터를 키우면 되기 때문에 규모 가변성이 가장 큰 장점이다.
- 범용 분산처리 플랫폼 게임을 만들면서도 분산처리에 응용할 수도 있음

#### Spark 분산처리의 예
- 사례1) 대용량 텍스트 로그 정리
 - 중복 및 오류가 있는 원천 로그 파일의 정리 과제
 - 한 달 에상 -> 30대 클러스터 분산으로 하루에 완료
 - 아마존 EMR로 분산처리, 로컬에서 코드 최적화도 하고 팁을 만들어낼 수도 있었겠지만 비용을 써서 빨리 해결할 수 있었음
- 사례2) 기계학습된 모델로 대량 검출
 - 학습된 랜덤포레스트 모델을 분산해 검출
 - 10배 이상의 속도 향상

#### 분산 검출의 예

#### Spark 환경 추천
- 아마존 같은 온디맨드 서비스를 사용
- 높은 가성비, 설치, 유지보수 등의 비용을 생각한다면 추천함
- 일반적으로 CSV, JSON 사용하는데 Parque, ORC 포맷을 이용하면 10배의 속도가 나온다.

#### 딥러닝 라이브러리
- 소프트웨어 2.0의 핵심
- 텐서플로우 : 넓은 레퍼런스 + 빠른 속도 -> 실제 서비스에 적합
- PyTorch : 간결함 + 디버깅 용이 -> 연구에 적합

#### 자동 미분 : 임의의 연산이 미분 가능
방정식 풀이, 파라메터 처리 등 다양한 용도로 사용할 수 있다.

### 참고 : 사용 중인 분석 시스템 구조
- 리얼타임 모니터링을 엘라스틱서치
- 사이킷런과 파이토치를 사용해서 분산 검출하고 있다.


## 사례

### 마르코프 이론
- 어뷰징 캐릭터(계정)는 소모품이다.
- 이름을 대충 랜덤하게 짓습니다.
- 이것을 정량화 할 수 있다면? 어뷰징 검출에 도움이 되지 않을까?

### 기존 랜덤 이름 검출 방식
 - 자/모음의 패턴
 - 수작업된 코드
 - 데이터로 학습할 수 없을까?

### 마르코프 연쇄
- 마르코프 성질 - 과거는 현재, 현재는 미래에 영향을 줌
- 날씨의 예 - SSSCRS 맑다가 흐리다 비가오는 일, 비가 오면 날씨가 갠다. 갠 날씨에서 갑자기 비가오는 확률은 적다.
- 일종의 전이확률로 파악할 수 있다.
- 영어 단어의 마르코프 연쇄
- 확률을 학습하기 위해 큰 코퍼스
- 문자를 2개씩 추출해서 어떤 문자 다음에 어떤 문자가 오더라는 것을 확률로 평균을 구함
- 문자간 전이 확률
- d 다음에 스페이스가 많이 나오는 것은 과거형이 많아서 일듯

- 이 확률을 계산해 랜덤한 확률을 구함
- 산출된 랜덤 점수의 예 : 이것을 분류기의 특성 중 하나로 하여 어뷰저 검출에 참고하여 정확도가 향상 됨

## Text CNN으로 스팸 검출
- 예전 정규식으로 스팸을 검출하면 창과 방패의 싸움이 이어짐
- 2016년 발표자료에서 통계적 스팸 검출방식은 임계치를 파악하여 어뷰저가 우회하기도 함

## CNN
- 이미지를 분류하기 위해 특징을 추출하는 방식
- 이미지 분류를 위해 만들어지기는 했지만 소리나 텍스트에도 많이 사용됨

### 목표
1. 기본 스팸 메시지에서 학습
2. 빈번한 모델 갱신이 필요 없게 - 잦은 유지보수 힘듦
3. 빠른 검출 시간

### 학습 준비
- 눈으로 직접 확인하며 학습 데이터를 수집했다.
- 스팸메시지는 빈도가 높으나 다양하지 않음

### 메시지를 임베딩
- 뉴럴넷는 숫자만 다룰 수 있기 때문에 적절하게 벡터화
- 대표적으로 원핫인코딩

### 단어 레벨 vs 캐릭터 레벨
- 일반적으로는 단어(Word) 레벨 임베딩이 많이 쓰임
- 채팅은 변칙적인 단어가 많아 임베딩이 곤란

### 다양한 크기의 커널 이용
- 다른 크기의 커널

### 합친 결과를 역전파로 학습

### 문제점
- 기본 스팸 메시지수는 극히 적음
- 일반 메시지 수는 아주 많음

### 변종 스팸 대응 문제


### 데이터 증강 + 드랍아웃으로 해결
- 데이터 증강 : 스팸 문자열 내 임의로 기호/공백 문자 섞기
- 드랍아웃 : 학습된 뉴런을 임의 삭제


### 기본 스팸 메시지들
- 영문자 대소문자는 구분하지 않는 것
- 대상 문자와 원핫인코딩 캐릭터 단위로


### TextCNN 모듈 정의
- 커널을 3, 4, 5, 6 다양하게 사용

### 학습 후 적용 결과
- 변형을 가한 문자에 대해서도 스팸을 판단한다.

### 주의점
- 일반 메시지라도 주요 단어가 들어가면 스팸 점수 상승
- 적절한 임계값과 빈도로 스패머 여부 판다

### 향상된 점
- 잦은 모델 업데이트 없이 변형 스팸 대응
- 일단위가 아닌 메시지 당 검출 가능

### 이동 변위 CNN으로 오토 검출
- 파밍 어뷰저의 가장 큰 특성?
- 반복적인 행동(오토)
- 이것이 어뷰징의 시작

### 기존 반복적 행동 검출 방법
- 몇 가지 통계적 수치를 조합해 판단
- 임계치에 민감

### 선례 : 자기 유사도를 이용한 탐지
- 이동 위치는 너무 엄밀, 우회가 용이

### 이동 경로가 아닌 이동 변위로 동작의 반복성을 살펴보면?

### 어뷰저의 변이 그래프 vs 정상 유저의 변이 그래프

### 왜 이런 패턴을 보일까? 학습 및 검출
1. 어뷰저 데이터 수작업 선별(150개) 정상 샘플은 전체에서 임의 추출
2. 고정 윈도우(1000개 변위)로 미니매치
3. 학습 시작 위치를 다양하게 해 클래스 불균형 완화
하나의 변위 데이터도 시작 위치에 따라 다름
4. 조기종료(오버피팅 방지)
5. 검출시는 윈도우 단위 판정값을 평균내어 판정(시계열)

### 초기 문제점
1. 정확도가 향상되지 않음
- 이동 병위값이 너무 크다. 정규화(Normalization) 적용
2. 가끔 손실 값이 튀는 현상
- 배치 Normalization 사용 후 완화
- 레이어와 레이어 사이의 값을 정규화 하는 방식
- BN적용 후 개선된 손실

### 초기 학습시 오탐한 데이터는 수작업 분류 후 학습
- 어뷰저로 오탐된 변이의 예
 - 쉬는 시간이 있음, 어뷰저는 이것을 파악하기 어려움
- 오탐 대응, 이동 변위 + 시간 변위 사용

### 미니 배치 순회

### 테스트셋으로 검증결과 정확도 97% 최종 제재는 다른 특성도 함께 고려

### 검출 결과

### 향상된 점
- 수작업 없는 빠른 검출

### 살펴본점

### 서비스 적용 현황
- 자동 제재 이후 지역별 검출 어뷰저 수 추세

### 앞으로의 과제
- 영어 외의 이름 스팸 검출은 까다로움
- 모바일 게임으로의 오토 검출
- 게임 데이터 라벨링 수단 - 전용 툴, [Amazon Mechanical Turk](https://www.mturk.com/)
- GAN 사용

### SW 2.0을 시도하려면
1. 이론 공부와 다양한 실험
2. 도메인 전문가와 이야기
3. 인프라 구축은 필요한 만큼만
4. 반복 학습 전에 데이터 확인과 코드리뷰 먼저

소프트웨어 1.0과 2.0의 미래

###  참고 FizzBuzz 문제

- 딥러닝 공부를 너무 많이 하다가 텐서플로우로 구현
- 그러나 불합격되었다는 짤방
- 모든 문제가 2.0 대상은 아니다.
- 1.0과 2.0의 앙상블로 문제를 해결


### 참고 링크 

* [Hands on Big Data by Peter Norvig](https://machinelearningmastery.com/hands-on-big-data-by-peter-norvig/)
* [Autograd: automatic differentiation — PyTorch Tutorials 0.4.0 documentation](http://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html#sphx-glr-beginner-blitz-autograd-tutorial-py)
* [마스터 알고리즘 (머신러닝은 우리의 미래를 어떻게 바꾸는가) - 리디북스](https://ridibooks.com/v2/Detail?id=1780000048)
* [rrenaud/Gibberish-Detector: A small program to detect gibberish using a Markov Chain](https://github.com/rrenaud/Gibberish-Detector)
* [자기 유사도를 이용한 MMORPG 게임봇 탐지 시스템 - 정보보호학회논문지 - 한국정보보호학회 : 전자저널 논문 - DBpia](http://www.dbpia.co.kr/Journal/ArticleDetail/NODE06617217)
