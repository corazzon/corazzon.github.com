---
layout: post
title: "[도서 리뷰] 트랜스포머를 활용한 자연어 처리"
tagline: "이 리뷰는 한빛미디어의 나는 리뷰어다 이벤트를 통해 책을 제공받아 작성했습니다."
description: "허깅페이스 개발팀이 알려주는 자연어 애플리케이션 구축"
category: 자연어 처리, 인공지능, 트랜스포머, NLP, AI, 머신러닝, GPT-3, 허깅페이스, NER, 질문 답변, 텍스트 생성, 텍스트 요약
---


<img src="https://i.imgur.com/GkxRq5i.jpg" width=600>



Attention is all you need 논문으로 큰 주목을 받은 Transformer로 자연어처리에서 좋은 성능을 내며 주목을 받고 있다.
요즘 나오는 초거대모델을 보면 곧 내 일자리를 잃지 않을까 혹은 지금까지 해왔던 자연어 공부가 무용해지는게 아닐까 싶을 정도로 초거대모델의 성능은 눈부시다.
광고문구, 비즈니스메일, 내용 요약 등 나보다도 작문을 잘하고 요약을 잘 하는 모습을 보면 놀라움을 감출 수 없다.
또, 요즘 나오는 모델은 API 사용법도 과거 모델에 비해 추상화가 잘 되어 있어 복잡한 내부를 잘 모르더라도 간단한 API 몇 가지를 읽히면 제법 그럴듯한 모델을 만들 수 있다.

하지만 그래도 기본을 닦고 관련 내용을 좀 더 알고 있다면 간단한 API라도 해당 모델에 맞게 전처리를 해주거나 튜닝을 해준다면 더 나은 성능을 낼것이다.

그런면에서 이 책은 트랜스포머에 대한 동작 원리를 이해하고 직접 모델을 사용해보는 예시가 풍부해서 트랜스포머를 익히기에 딱 좋을 뿐만아니라 한줄기 빛과도 같은 책이다.


<img src="https://i.imgur.com/COpsh5j.jpg" width=600>

주요 내용으로는 기본적인 텍스트 분류부터, 개체명 인식, 전이학습 활용법, 파인튜닝, 모델 평가하고 성능을 높이는 방법등 실무에 필요한 팁들을 정리하고 있다.

* 텍스트 분류, 개체명 인식 등 NLP 작업을 위한 트랜스포머 모델을 빌드 및 디버깅, 최적화하는 방법
* 언어 간 전이 학습에 트랜스포머를 사용하는 방법
* 레이블링된 데이터가 부족한 상황에서 트랜스포머를 적용해 모델 성능을 높이는 방법
* 지식 정제와 양자화, 가지치기 같은 기술을 사용한 트랜스포머 모델 효율화 방법
* 대규모 트랜스포머 모델을 밑바닥부터 훈련하고 여러 GPU 및 분산 환경으로 확장하는 방법


<img src="https://i.imgur.com/XHuPV6K.jpg" width=600>


<img src="https://i.imgur.com/Vqu08wM.jpg" width=600>

또, 최근 생성모델이 많은 주목을 받고 있는데 텍스트 생성시 고려할 디코딩 방법등에 대해 소개하고 있다.
질문 답변에서의 활용방법이나 효율적인 모델 구축방법을 소개하고 있으며, 
데이터셋 구축이나 레이블 부족문제와 같은 실무에서 고민했던 문제에 대해 다루는 부분도 인상적이다.


<img src="https://i.imgur.com/mX5uX7V.jpg" width=600>


<img src="https://i.imgur.com/9kmJS1z.jpg" width=600>


<img src="https://i.imgur.com/0DXVycB.jpg" width=600>

앞으로의 연구방향이나 여러 어텐션 방법 등에 대해 컬러 예제를 통해 이해를 돕는 것도 좋다.
또, 꼼꼼하신 역자분이 번역해주셔서 어려운 내용을 좀 더 쉽게 읽어볼 수 있는 것도 감사한 점이다.
개인적으로 자연어처리에 관심이 많은데 상세한 설명과 함께 컬러 도표와 함께 볼 수 있어서 너무나 좋았던 책이다.

역자분이 깃헙에 소스코드도 너무 친절하게 정리해 주셔서 이해에 정말 큰 도움이 되었다.

https://github.com/rickiepark/nlp-with-transformers

트랜스포머 관련 정리된 책이 많지 않은데 이렇게 한권의 꼼꼼하게 번역된 책으로 배울 수 있다는게 얼마나 행운인지 모른다.

이 리뷰는 한빛미디어의 나는 리뷰어다 이벤트를 통해 책을 제공받아 작성했습니다.
